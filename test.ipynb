{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#预训练的vit模型\n",
    "class ViTBase16(nn.Module):\n",
    "    def __init__(self, model_name='vit_base_patch16_224', pretrained=False):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(model_name, pretrained=pretrained)\n",
    "        self.model.head = nn.Linear(self.model.head.in_features, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "150c81fbac124c30bb2239cd5890ccd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading model.safetensors', max=346284714.0, style=Pr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "model.cls_token torch.Size([1, 1, 768])\n",
      "model.pos_embed torch.Size([1, 197, 768])\n",
      "model.patch_embed.proj.weight torch.Size([768, 3, 16, 16])\n",
      "model.patch_embed.proj.bias torch.Size([768])\n",
      "model.blocks.0.norm1.weight torch.Size([768])\n",
      "model.blocks.0.norm1.bias torch.Size([768])\n",
      "model.blocks.0.attn.qkv.weight torch.Size([2304, 768])\n",
      "model.blocks.0.attn.qkv.bias torch.Size([2304])\n",
      "model.blocks.0.attn.proj.weight torch.Size([768, 768])\n",
      "model.blocks.0.attn.proj.bias torch.Size([768])\n",
      "model.blocks.0.norm2.weight torch.Size([768])\n",
      "model.blocks.0.norm2.bias torch.Size([768])\n",
      "model.blocks.0.mlp.fc1.weight torch.Size([3072, 768])\n",
      "model.blocks.0.mlp.fc1.bias torch.Size([3072])\n",
      "model.blocks.0.mlp.fc2.weight torch.Size([768, 3072])\n",
      "model.blocks.0.mlp.fc2.bias torch.Size([768])\n",
      "model.blocks.1.norm1.weight torch.Size([768])\n",
      "model.blocks.1.norm1.bias torch.Size([768])\n",
      "model.blocks.1.attn.qkv.weight torch.Size([2304, 768])\n",
      "model.blocks.1.attn.qkv.bias torch.Size([2304])\n",
      "model.blocks.1.attn.proj.weight torch.Size([768, 768])\n",
      "model.blocks.1.attn.proj.bias torch.Size([768])\n",
      "model.blocks.1.norm2.weight torch.Size([768])\n",
      "model.blocks.1.norm2.bias torch.Size([768])\n",
      "model.blocks.1.mlp.fc1.weight torch.Size([3072, 768])\n",
      "model.blocks.1.mlp.fc1.bias torch.Size([3072])\n",
      "model.blocks.1.mlp.fc2.weight torch.Size([768, 3072])\n",
      "model.blocks.1.mlp.fc2.bias torch.Size([768])\n",
      "model.blocks.2.norm1.weight torch.Size([768])\n",
      "model.blocks.2.norm1.bias torch.Size([768])\n",
      "model.blocks.2.attn.qkv.weight torch.Size([2304, 768])\n",
      "model.blocks.2.attn.qkv.bias torch.Size([2304])\n",
      "model.blocks.2.attn.proj.weight torch.Size([768, 768])\n",
      "model.blocks.2.attn.proj.bias torch.Size([768])\n",
      "model.blocks.2.norm2.weight torch.Size([768])\n",
      "model.blocks.2.norm2.bias torch.Size([768])\n",
      "model.blocks.2.mlp.fc1.weight torch.Size([3072, 768])\n",
      "model.blocks.2.mlp.fc1.bias torch.Size([3072])\n",
      "model.blocks.2.mlp.fc2.weight torch.Size([768, 3072])\n",
      "model.blocks.2.mlp.fc2.bias torch.Size([768])\n",
      "model.blocks.3.norm1.weight torch.Size([768])\n",
      "model.blocks.3.norm1.bias torch.Size([768])\n",
      "model.blocks.3.attn.qkv.weight torch.Size([2304, 768])\n",
      "model.blocks.3.attn.qkv.bias torch.Size([2304])\n",
      "model.blocks.3.attn.proj.weight torch.Size([768, 768])\n",
      "model.blocks.3.attn.proj.bias torch.Size([768])\n",
      "model.blocks.3.norm2.weight torch.Size([768])\n",
      "model.blocks.3.norm2.bias torch.Size([768])\n",
      "model.blocks.3.mlp.fc1.weight torch.Size([3072, 768])\n",
      "model.blocks.3.mlp.fc1.bias torch.Size([3072])\n",
      "model.blocks.3.mlp.fc2.weight torch.Size([768, 3072])\n",
      "model.blocks.3.mlp.fc2.bias torch.Size([768])\n",
      "model.blocks.4.norm1.weight torch.Size([768])\n",
      "model.blocks.4.norm1.bias torch.Size([768])\n",
      "model.blocks.4.attn.qkv.weight torch.Size([2304, 768])\n",
      "model.blocks.4.attn.qkv.bias torch.Size([2304])\n",
      "model.blocks.4.attn.proj.weight torch.Size([768, 768])\n",
      "model.blocks.4.attn.proj.bias torch.Size([768])\n",
      "model.blocks.4.norm2.weight torch.Size([768])\n",
      "model.blocks.4.norm2.bias torch.Size([768])\n",
      "model.blocks.4.mlp.fc1.weight torch.Size([3072, 768])\n",
      "model.blocks.4.mlp.fc1.bias torch.Size([3072])\n",
      "model.blocks.4.mlp.fc2.weight torch.Size([768, 3072])\n",
      "model.blocks.4.mlp.fc2.bias torch.Size([768])\n",
      "model.blocks.5.norm1.weight torch.Size([768])\n",
      "model.blocks.5.norm1.bias torch.Size([768])\n",
      "model.blocks.5.attn.qkv.weight torch.Size([2304, 768])\n",
      "model.blocks.5.attn.qkv.bias torch.Size([2304])\n",
      "model.blocks.5.attn.proj.weight torch.Size([768, 768])\n",
      "model.blocks.5.attn.proj.bias torch.Size([768])\n",
      "model.blocks.5.norm2.weight torch.Size([768])\n",
      "model.blocks.5.norm2.bias torch.Size([768])\n",
      "model.blocks.5.mlp.fc1.weight torch.Size([3072, 768])\n",
      "model.blocks.5.mlp.fc1.bias torch.Size([3072])\n",
      "model.blocks.5.mlp.fc2.weight torch.Size([768, 3072])\n",
      "model.blocks.5.mlp.fc2.bias torch.Size([768])\n",
      "model.blocks.6.norm1.weight torch.Size([768])\n",
      "model.blocks.6.norm1.bias torch.Size([768])\n",
      "model.blocks.6.attn.qkv.weight torch.Size([2304, 768])\n",
      "model.blocks.6.attn.qkv.bias torch.Size([2304])\n",
      "model.blocks.6.attn.proj.weight torch.Size([768, 768])\n",
      "model.blocks.6.attn.proj.bias torch.Size([768])\n",
      "model.blocks.6.norm2.weight torch.Size([768])\n",
      "model.blocks.6.norm2.bias torch.Size([768])\n",
      "model.blocks.6.mlp.fc1.weight torch.Size([3072, 768])\n",
      "model.blocks.6.mlp.fc1.bias torch.Size([3072])\n",
      "model.blocks.6.mlp.fc2.weight torch.Size([768, 3072])\n",
      "model.blocks.6.mlp.fc2.bias torch.Size([768])\n",
      "model.blocks.7.norm1.weight torch.Size([768])\n",
      "model.blocks.7.norm1.bias torch.Size([768])\n",
      "model.blocks.7.attn.qkv.weight torch.Size([2304, 768])\n",
      "model.blocks.7.attn.qkv.bias torch.Size([2304])\n",
      "model.blocks.7.attn.proj.weight torch.Size([768, 768])\n",
      "model.blocks.7.attn.proj.bias torch.Size([768])\n",
      "model.blocks.7.norm2.weight torch.Size([768])\n",
      "model.blocks.7.norm2.bias torch.Size([768])\n",
      "model.blocks.7.mlp.fc1.weight torch.Size([3072, 768])\n",
      "model.blocks.7.mlp.fc1.bias torch.Size([3072])\n",
      "model.blocks.7.mlp.fc2.weight torch.Size([768, 3072])\n",
      "model.blocks.7.mlp.fc2.bias torch.Size([768])\n",
      "model.blocks.8.norm1.weight torch.Size([768])\n",
      "model.blocks.8.norm1.bias torch.Size([768])\n",
      "model.blocks.8.attn.qkv.weight torch.Size([2304, 768])\n",
      "model.blocks.8.attn.qkv.bias torch.Size([2304])\n",
      "model.blocks.8.attn.proj.weight torch.Size([768, 768])\n",
      "model.blocks.8.attn.proj.bias torch.Size([768])\n",
      "model.blocks.8.norm2.weight torch.Size([768])\n",
      "model.blocks.8.norm2.bias torch.Size([768])\n",
      "model.blocks.8.mlp.fc1.weight torch.Size([3072, 768])\n",
      "model.blocks.8.mlp.fc1.bias torch.Size([3072])\n",
      "model.blocks.8.mlp.fc2.weight torch.Size([768, 3072])\n",
      "model.blocks.8.mlp.fc2.bias torch.Size([768])\n",
      "model.blocks.9.norm1.weight torch.Size([768])\n",
      "model.blocks.9.norm1.bias torch.Size([768])\n",
      "model.blocks.9.attn.qkv.weight torch.Size([2304, 768])\n",
      "model.blocks.9.attn.qkv.bias torch.Size([2304])\n",
      "model.blocks.9.attn.proj.weight torch.Size([768, 768])\n",
      "model.blocks.9.attn.proj.bias torch.Size([768])\n",
      "model.blocks.9.norm2.weight torch.Size([768])\n",
      "model.blocks.9.norm2.bias torch.Size([768])\n",
      "model.blocks.9.mlp.fc1.weight torch.Size([3072, 768])\n",
      "model.blocks.9.mlp.fc1.bias torch.Size([3072])\n",
      "model.blocks.9.mlp.fc2.weight torch.Size([768, 3072])\n",
      "model.blocks.9.mlp.fc2.bias torch.Size([768])\n",
      "model.blocks.10.norm1.weight torch.Size([768])\n",
      "model.blocks.10.norm1.bias torch.Size([768])\n",
      "model.blocks.10.attn.qkv.weight torch.Size([2304, 768])\n",
      "model.blocks.10.attn.qkv.bias torch.Size([2304])\n",
      "model.blocks.10.attn.proj.weight torch.Size([768, 768])\n",
      "model.blocks.10.attn.proj.bias torch.Size([768])\n",
      "model.blocks.10.norm2.weight torch.Size([768])\n",
      "model.blocks.10.norm2.bias torch.Size([768])\n",
      "model.blocks.10.mlp.fc1.weight torch.Size([3072, 768])\n",
      "model.blocks.10.mlp.fc1.bias torch.Size([3072])\n",
      "model.blocks.10.mlp.fc2.weight torch.Size([768, 3072])\n",
      "model.blocks.10.mlp.fc2.bias torch.Size([768])\n",
      "model.blocks.11.norm1.weight torch.Size([768])\n",
      "model.blocks.11.norm1.bias torch.Size([768])\n",
      "model.blocks.11.attn.qkv.weight torch.Size([2304, 768])\n",
      "model.blocks.11.attn.qkv.bias torch.Size([2304])\n",
      "model.blocks.11.attn.proj.weight torch.Size([768, 768])\n",
      "model.blocks.11.attn.proj.bias torch.Size([768])\n",
      "model.blocks.11.norm2.weight torch.Size([768])\n",
      "model.blocks.11.norm2.bias torch.Size([768])\n",
      "model.blocks.11.mlp.fc1.weight torch.Size([3072, 768])\n",
      "model.blocks.11.mlp.fc1.bias torch.Size([3072])\n",
      "model.blocks.11.mlp.fc2.weight torch.Size([768, 3072])\n",
      "model.blocks.11.mlp.fc2.bias torch.Size([768])\n",
      "model.norm.weight torch.Size([768])\n",
      "model.norm.bias torch.Size([768])\n",
      "model.head.weight torch.Size([10, 768])\n",
      "model.head.bias torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "model = ViTBase16(pretrained=True)\n",
    "for name, param in model.named_parameters():\n",
    "    print(name, param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/facebookresearch_deit_main\n",
      "Downloading: \"https://dl.fbaipublicfiles.com/deit/deit_tiny_patch16_224-a1311bcf.pth\" to /root/.cache/torch/hub/checkpoints/deit_tiny_patch16_224-a1311bcf.pth\n",
      "100%|██████████| 21.9M/21.9M [00:03<00:00, 7.64MB/s]\n"
     ]
    }
   ],
   "source": [
    "deit = torch.hub.load('facebookresearch/deit:main', 'deit_tiny_patch16_224', pretrained=True)\n",
    "deit.head = nn.Linear(deit.head.in_features, 10)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls_token torch.Size([1, 1, 192])\n",
      "pos_embed torch.Size([1, 197, 192])\n",
      "patch_embed.proj.weight torch.Size([192, 3, 16, 16])\n",
      "patch_embed.proj.bias torch.Size([192])\n",
      "blocks.0.norm1.weight torch.Size([192])\n",
      "blocks.0.norm1.bias torch.Size([192])\n",
      "blocks.0.attn.qkv.weight torch.Size([576, 192])\n",
      "blocks.0.attn.qkv.bias torch.Size([576])\n",
      "blocks.0.attn.proj.weight torch.Size([192, 192])\n",
      "blocks.0.attn.proj.bias torch.Size([192])\n",
      "blocks.0.norm2.weight torch.Size([192])\n",
      "blocks.0.norm2.bias torch.Size([192])\n",
      "blocks.0.mlp.fc1.weight torch.Size([768, 192])\n",
      "blocks.0.mlp.fc1.bias torch.Size([768])\n",
      "blocks.0.mlp.fc2.weight torch.Size([192, 768])\n",
      "blocks.0.mlp.fc2.bias torch.Size([192])\n",
      "blocks.1.norm1.weight torch.Size([192])\n",
      "blocks.1.norm1.bias torch.Size([192])\n",
      "blocks.1.attn.qkv.weight torch.Size([576, 192])\n",
      "blocks.1.attn.qkv.bias torch.Size([576])\n",
      "blocks.1.attn.proj.weight torch.Size([192, 192])\n",
      "blocks.1.attn.proj.bias torch.Size([192])\n",
      "blocks.1.norm2.weight torch.Size([192])\n",
      "blocks.1.norm2.bias torch.Size([192])\n",
      "blocks.1.mlp.fc1.weight torch.Size([768, 192])\n",
      "blocks.1.mlp.fc1.bias torch.Size([768])\n",
      "blocks.1.mlp.fc2.weight torch.Size([192, 768])\n",
      "blocks.1.mlp.fc2.bias torch.Size([192])\n",
      "blocks.2.norm1.weight torch.Size([192])\n",
      "blocks.2.norm1.bias torch.Size([192])\n",
      "blocks.2.attn.qkv.weight torch.Size([576, 192])\n",
      "blocks.2.attn.qkv.bias torch.Size([576])\n",
      "blocks.2.attn.proj.weight torch.Size([192, 192])\n",
      "blocks.2.attn.proj.bias torch.Size([192])\n",
      "blocks.2.norm2.weight torch.Size([192])\n",
      "blocks.2.norm2.bias torch.Size([192])\n",
      "blocks.2.mlp.fc1.weight torch.Size([768, 192])\n",
      "blocks.2.mlp.fc1.bias torch.Size([768])\n",
      "blocks.2.mlp.fc2.weight torch.Size([192, 768])\n",
      "blocks.2.mlp.fc2.bias torch.Size([192])\n",
      "blocks.3.norm1.weight torch.Size([192])\n",
      "blocks.3.norm1.bias torch.Size([192])\n",
      "blocks.3.attn.qkv.weight torch.Size([576, 192])\n",
      "blocks.3.attn.qkv.bias torch.Size([576])\n",
      "blocks.3.attn.proj.weight torch.Size([192, 192])\n",
      "blocks.3.attn.proj.bias torch.Size([192])\n",
      "blocks.3.norm2.weight torch.Size([192])\n",
      "blocks.3.norm2.bias torch.Size([192])\n",
      "blocks.3.mlp.fc1.weight torch.Size([768, 192])\n",
      "blocks.3.mlp.fc1.bias torch.Size([768])\n",
      "blocks.3.mlp.fc2.weight torch.Size([192, 768])\n",
      "blocks.3.mlp.fc2.bias torch.Size([192])\n",
      "blocks.4.norm1.weight torch.Size([192])\n",
      "blocks.4.norm1.bias torch.Size([192])\n",
      "blocks.4.attn.qkv.weight torch.Size([576, 192])\n",
      "blocks.4.attn.qkv.bias torch.Size([576])\n",
      "blocks.4.attn.proj.weight torch.Size([192, 192])\n",
      "blocks.4.attn.proj.bias torch.Size([192])\n",
      "blocks.4.norm2.weight torch.Size([192])\n",
      "blocks.4.norm2.bias torch.Size([192])\n",
      "blocks.4.mlp.fc1.weight torch.Size([768, 192])\n",
      "blocks.4.mlp.fc1.bias torch.Size([768])\n",
      "blocks.4.mlp.fc2.weight torch.Size([192, 768])\n",
      "blocks.4.mlp.fc2.bias torch.Size([192])\n",
      "blocks.5.norm1.weight torch.Size([192])\n",
      "blocks.5.norm1.bias torch.Size([192])\n",
      "blocks.5.attn.qkv.weight torch.Size([576, 192])\n",
      "blocks.5.attn.qkv.bias torch.Size([576])\n",
      "blocks.5.attn.proj.weight torch.Size([192, 192])\n",
      "blocks.5.attn.proj.bias torch.Size([192])\n",
      "blocks.5.norm2.weight torch.Size([192])\n",
      "blocks.5.norm2.bias torch.Size([192])\n",
      "blocks.5.mlp.fc1.weight torch.Size([768, 192])\n",
      "blocks.5.mlp.fc1.bias torch.Size([768])\n",
      "blocks.5.mlp.fc2.weight torch.Size([192, 768])\n",
      "blocks.5.mlp.fc2.bias torch.Size([192])\n",
      "blocks.6.norm1.weight torch.Size([192])\n",
      "blocks.6.norm1.bias torch.Size([192])\n",
      "blocks.6.attn.qkv.weight torch.Size([576, 192])\n",
      "blocks.6.attn.qkv.bias torch.Size([576])\n",
      "blocks.6.attn.proj.weight torch.Size([192, 192])\n",
      "blocks.6.attn.proj.bias torch.Size([192])\n",
      "blocks.6.norm2.weight torch.Size([192])\n",
      "blocks.6.norm2.bias torch.Size([192])\n",
      "blocks.6.mlp.fc1.weight torch.Size([768, 192])\n",
      "blocks.6.mlp.fc1.bias torch.Size([768])\n",
      "blocks.6.mlp.fc2.weight torch.Size([192, 768])\n",
      "blocks.6.mlp.fc2.bias torch.Size([192])\n",
      "blocks.7.norm1.weight torch.Size([192])\n",
      "blocks.7.norm1.bias torch.Size([192])\n",
      "blocks.7.attn.qkv.weight torch.Size([576, 192])\n",
      "blocks.7.attn.qkv.bias torch.Size([576])\n",
      "blocks.7.attn.proj.weight torch.Size([192, 192])\n",
      "blocks.7.attn.proj.bias torch.Size([192])\n",
      "blocks.7.norm2.weight torch.Size([192])\n",
      "blocks.7.norm2.bias torch.Size([192])\n",
      "blocks.7.mlp.fc1.weight torch.Size([768, 192])\n",
      "blocks.7.mlp.fc1.bias torch.Size([768])\n",
      "blocks.7.mlp.fc2.weight torch.Size([192, 768])\n",
      "blocks.7.mlp.fc2.bias torch.Size([192])\n",
      "blocks.8.norm1.weight torch.Size([192])\n",
      "blocks.8.norm1.bias torch.Size([192])\n",
      "blocks.8.attn.qkv.weight torch.Size([576, 192])\n",
      "blocks.8.attn.qkv.bias torch.Size([576])\n",
      "blocks.8.attn.proj.weight torch.Size([192, 192])\n",
      "blocks.8.attn.proj.bias torch.Size([192])\n",
      "blocks.8.norm2.weight torch.Size([192])\n",
      "blocks.8.norm2.bias torch.Size([192])\n",
      "blocks.8.mlp.fc1.weight torch.Size([768, 192])\n",
      "blocks.8.mlp.fc1.bias torch.Size([768])\n",
      "blocks.8.mlp.fc2.weight torch.Size([192, 768])\n",
      "blocks.8.mlp.fc2.bias torch.Size([192])\n",
      "blocks.9.norm1.weight torch.Size([192])\n",
      "blocks.9.norm1.bias torch.Size([192])\n",
      "blocks.9.attn.qkv.weight torch.Size([576, 192])\n",
      "blocks.9.attn.qkv.bias torch.Size([576])\n",
      "blocks.9.attn.proj.weight torch.Size([192, 192])\n",
      "blocks.9.attn.proj.bias torch.Size([192])\n",
      "blocks.9.norm2.weight torch.Size([192])\n",
      "blocks.9.norm2.bias torch.Size([192])\n",
      "blocks.9.mlp.fc1.weight torch.Size([768, 192])\n",
      "blocks.9.mlp.fc1.bias torch.Size([768])\n",
      "blocks.9.mlp.fc2.weight torch.Size([192, 768])\n",
      "blocks.9.mlp.fc2.bias torch.Size([192])\n",
      "blocks.10.norm1.weight torch.Size([192])\n",
      "blocks.10.norm1.bias torch.Size([192])\n",
      "blocks.10.attn.qkv.weight torch.Size([576, 192])\n",
      "blocks.10.attn.qkv.bias torch.Size([576])\n",
      "blocks.10.attn.proj.weight torch.Size([192, 192])\n",
      "blocks.10.attn.proj.bias torch.Size([192])\n",
      "blocks.10.norm2.weight torch.Size([192])\n",
      "blocks.10.norm2.bias torch.Size([192])\n",
      "blocks.10.mlp.fc1.weight torch.Size([768, 192])\n",
      "blocks.10.mlp.fc1.bias torch.Size([768])\n",
      "blocks.10.mlp.fc2.weight torch.Size([192, 768])\n",
      "blocks.10.mlp.fc2.bias torch.Size([192])\n",
      "blocks.11.norm1.weight torch.Size([192])\n",
      "blocks.11.norm1.bias torch.Size([192])\n",
      "blocks.11.attn.qkv.weight torch.Size([576, 192])\n",
      "blocks.11.attn.qkv.bias torch.Size([576])\n",
      "blocks.11.attn.proj.weight torch.Size([192, 192])\n",
      "blocks.11.attn.proj.bias torch.Size([192])\n",
      "blocks.11.norm2.weight torch.Size([192])\n",
      "blocks.11.norm2.bias torch.Size([192])\n",
      "blocks.11.mlp.fc1.weight torch.Size([768, 192])\n",
      "blocks.11.mlp.fc1.bias torch.Size([768])\n",
      "blocks.11.mlp.fc2.weight torch.Size([192, 768])\n",
      "blocks.11.mlp.fc2.bias torch.Size([192])\n",
      "norm.weight torch.Size([192])\n",
      "norm.bias torch.Size([192])\n",
      "head.weight torch.Size([10, 192])\n",
      "head.bias torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for name,param in deit.named_parameters():\n",
    "    print(name,param.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
